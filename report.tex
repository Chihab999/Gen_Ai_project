\documentclass[a4paper,12pt]{report}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[french]{babel}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{float}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{xcolor}
\usepackage{csquotes}
\usepackage{fancyhdr}
\usepackage{titlesec}
\usepackage{setspace}

% --- Configuration de la mise en page ---
\geometry{top=2.5cm, bottom=2.5cm, left=2.5cm, right=2.5cm}
\setlength{\headheight}{15pt}
\onehalfspacing

% --- Configuration des En-têtes et Pieds de page ---
\pagestyle{fancy}
\fancyhf{}
\lhead{\small \textit{Découverte de molécules - Master Data Science}}
\rhead{\small \thepage}
\cfoot{}

% --- Configuration des Titres ---
\titleformat{\chapter}[display]
  {\normalfont\bfseries}{}{0pt}{\Huge}
\titlespacing*{\chapter}{0pt}{-50pt}{40pt}

% --- Gestion de la bibliographie ---
\usepackage[backend=biber,style=ieee]{biblatex}
\addbibresource{references.bib}

\begin{document}

% --- Page de Garde ---
\begin{titlepage}
    \centering
    \vspace*{1cm}
    
    {\Large \textbf{Faculté Polydisciplinaire de Safi}}\\[0.5cm]
    {\large Université Cadi Ayyad}\\[2cm]
    
    \includegraphics[width=0.3\textwidth]{assets/logo_placeholder.png} % Placeholder logo
    
    \vspace{2cm}
    
    {\Huge \textbf{Découverte de molécules pour nouveaux médicaments}}\\[0.8cm]
    {\LARGE \textit{Fusion GraphVAE, GraphGAN et Diffusion pour concevoir des structures moléculaires innovantes}}\\[2cm]
    
    \textbf{Rapport de Projet - Master Data Science et Intelligence Artificielle}\\[2cm]
    
    \begin{minipage}{0.4\textwidth}
        \begin{flushleft} \large
            \textbf{Réalisé par :}\\
            Chihab \textsc{Ouchen}\\
            \small \texttt{chihab.ouchen@gmail.com}\\[0.2cm]
            Ahmed \textsc{Ouidani}\\
            \small \texttt{ahmed.ouidani@gmail.com}
        \end{flushleft}
    \end{minipage}
    \begin{minipage}{0.4\textwidth}
        \begin{flushright} \large
            \textbf{Encadré par :}\\
            Pr. [Nom de l'encadrant]\\
            \small [Département]
        \end{flushright}
    \end{minipage}
    
    \vfill
    
    {\large Année Universitaire 2025-2026}
    
\end{titlepage}

% --- Résumé et Remerciements ---
\chapter*{Résumé}
Ce projet s'inscrit dans le cadre de la recherche en intelligence artificielle appliquée à la santé, spécifiquement la découverte de médicaments (\textit{Drug Discovery}). L'objectif est de générer de nouvelles structures moléculaires valides et dotées de propriétés pharmacologiques intéressantes (QED, Solubilité) en utilisant des modèles génératifs profonds.

Nous avons développé et analysé trois architectures hybrides distinctes :
\begin{enumerate}
    \item \textbf{Graph GAN-VAE} : Une fusion entre l'espace latent structuré des VAE et la capacité de génération réaliste des GANs.
    \item \textbf{C-GLD (Conditional Graph Latent Diffusion)} : Un modèle de diffusion opérant dans un espace latent compressé.
    \item \textbf{Ultimate Gen} : Une architecture de pointe combinant Graph Transformers pour l'encodage des dépendances atomiques distantes et un processus de diffusion pour la génération itérative.
\end{enumerate}

Nos expérimentations sur le dataset QM9 montrent que nous avons atteint une validité chimique de \textbf{100\%} et une nouveauté de \textbf{100\%}, surpassant plusieurs benchmarks classiques. Ce rapport détaille les fondements mathématiques, les choix architecturaux, et une analyse critique des résultats obtenus.

\vspace{1cm}
\textbf{Mots-clés :} Deep Learning Géométrique, Graph Neural Networks, VAE, GAN, Modèles de Diffusion, Drug Discovery, QM9.

\newpage
\chapter*{Plan du rapport}
\tableofcontents

% --- Introduction ---
\chapter{Introduction}

\section{Contexte Général : La crise de l'innovation pharmaceutique}
L'industrie pharmaceutique mondiale traverse actuellement une période paradoxale. D'un côté, les avancées en génomique et en biologie structurale n'ont jamais été aussi rapides, offrant une compréhension sans précédent des mécanismes pathologiques. De l'autre, la productivité de la R\&D pharmaceutique est en déclin constant. Ce phénomène, baptisé "Loi d'Eroom" (l'inverse de la loi de Moore), stipule que le coût de développement d'un nouveau médicament double environ tous les neuf ans.

Aujourd'hui, la mise sur le marché d'une nouvelle entité chimique (NCE) nécessite en moyenne :
\begin{itemize}
    \item \textbf{Durée} : 10 à 15 ans de développement.
    \item \textbf{Coût} : Plus de 2,5 milliards de dollars (coût capitalisé).
    \item \textbf{Risque} : Un taux d'échec supérieur à 90 \% lors des essais cliniques.
\end{itemize}

Une part significative de ces échecs est attribuable à la phase de "Drug Discovery", où les molécules identifiées comme prometteuses (Hits) se révèlent par la suite toxiques, inefficaces ou instables métaboliquement. L'optimisation précoce de ces propriétés est donc un levier économique et sanitaire majeur.

\section{La Problématique de l'Espace Chimique}
Le défi fondamental de la découverte de médicaments réside dans la taille de l'espace de recherche. L'espace chimique des petites molécules organiques "médicamentables" (drug-like) est estimé à environ $10^{60}$ structures possibles. À titre de comparaison, le nombre d'étoiles dans l'univers observable est de l'ordre de $10^{22}$.

Les méthodes traditionnelles, telles que le criblage à haut débit (High-Throughput Screening - HTS), permettent de tester physiquement quelques millions de molécules ($10^6$), ce qui reste une goutte d'eau dans l'océan chimique. L'approche inverse, consistant à concevoir rationnellement une molécule pour une cible donnée ("Rational Drug Design"), est limitée par notre capacité à modéliser les interactions complexes de la mécanique quantique et de la thermodynamique.

C'est ici qu'intervient l'Intelligence Artificielle Générative. Au lieu de cribler des banques existantes, l'idée est d'apprendre la distribution de probabilité sous-jacente aux molécules valides pour en "générer" de nouvelles qui maximisent certaines propriétés cibles.

\section{Défis du Deep Learning sur les Graphes Moléculaires}
Contrairement à la génération d'images (grille de pixels régulière) ou de texte (séquence linéaire), la génération de molécules pose des défis topologiques uniques :
\begin{enumerate}
    \item \textbf{Invariance par Permutation} : Un graphe peut être représenté par $N!$ matrices d'adjacence différentes, qui représentent toutes la même molécule. Le modèle doit être invariant à ces permutations.
    \item \textbf{Contraintes de Valence (Validité)} : Chaque atome a un nombre maximal de liaisons possibles (Carbone : 4, Azote : 3, etc.). Un modèle génératif naïf produira des graphes invalides chimiquement.
    \item \textbf{Discrétude et Non-Différentiabilité} : L'ajout d'une arête ou d'un atome est une opération discrète, rendant l'application directe de la descente de gradient (Backpropagation) difficile.
\end{enumerate}

\section{Objectifs et Contributions du Projet}
Dans ce projet de fin d'études, nous proposons d'explorer et de comparer trois architectures de pointe pour la génération moléculaire, visant à surmonter les limitations susmentionnées :
\begin{itemize}
    \item \textbf{Graph GAN-VAE \& GraphGAN} : Une approche hybride combinant la structuration de l'espace latent des VAEs avec la puissance de discrimination des GANs.
    \item \textbf{C-GLD (Conditional Graph Latent Diffusion)} : Une adaptation des modèles de diffusion (qui ont révolutionné la génération d'images) pour opérer dans l'espace latent d'un graphe.
    \item \textbf{Ultimate Gen} : Une architecture novatrice intégrant des mécanismes d'attention (Graph Transformers) et de diffusion conditionnelle pour une génération haute-fidélité.
\end{itemize}

Notre objectif est de générer des molécules qui sont non seulement \textbf{valides} et \textbf{uniques}, mais aussi \textbf{nouvelles} (non présentes dans les données d'entraînement) et optimisées pour des propriétés pharmacologiques comme le QED (Quantitative Estimation of Drug-likeness) et le LogP (Coefficient de partage octanol-eau).

% --- État de l'art ---
\chapter{État de l'art et Fondements Théoriques}

Ce chapitre détaille les fondements mathématiques des modèles génératifs profonds et leur application aux structures de graphes.

\section{Graphes et Message Passing Neural Networks (MPNN)}
Une molécule est modélisée par un graphe non orienté $G = (V, E)$, avec $N = |V|$ atomes.
\begin{itemize}
    \item La matrice de caractéristiques $X \in \mathbb{R}^{N \times F}$ décrit les propriétés atomiques (type, charge, hybridation).
    \item La matrice d'adjacence $A \in \{0, 1\}^{N \times N}$ (ou $A \in \mathbb{R}^{N \times N \times T}$ pour les types de liaisons) décrit la connectivité.
\end{itemize}

Les MPNNs généralisent la convolution aux graphes irréguliers. Pour chaque nœud $v$, l'état caché $h_v^{(l)}$ à la couche $l$ est mis à jour selon :
\begin{equation}
    h_v^{(l+1)} = \text{UPDATE}^{(l)} \left( h_v^{(l)}, \text{AGGREGATE}^{(l)} \left( \{ h_u^{(l)}, \forall u \in \mathcal{N}(v) \} \right) \right)
\end{equation}
Dans nos modèles, nous utilisons principalement \textbf{GATv2 (Graph Attention Networks v2)}, qui introduit un mécanisme d'attention dynamique pour pondérer l'importance des voisins, crucial pour capturer les effets électroniques subtils dans les molécules \cite{gatv2}.

\section{Auto-encodeurs Variationnels (VAE)}
Les VAEs apprennent une représentation compressée $z$ des données. L'encodeur $q_\phi(z|x)$ approxime la distribution a posteriori, et le décodeur $p_\theta(x|z)$ reconstruit la donnée. La fonction objective est la borne inférieure de la vraisemblance (ELBO - Evidence Lower Bound) \cite{kingma2013auto} :
\begin{equation}
    \mathcal{L}_{\text{VAE}} (x) = \mathbb{E}_{z \sim q_\phi(z|x)} [\log p_\theta(x|z)] - \beta D_{KL}(q_\phi(z|x) || p(z))
\end{equation}
Le terme de reconstruction assure la fidélité, tandis que le terme de divergence KL (Kullback-Leibler) force l'espace latent à suivre une distribution normale standard $\mathcal{N}(0, I)$, permettant l'échantillonnage génératif.

\section{Réseaux Antagonistes Génératifs (GAN)}
Les GANs reposent sur la théorie des jeux. Un générateur $G$ transforme un bruit $z$ en donnée synthétique $G(z)$, tandis qu'un discriminateur $D$ tente de classifier les échantillons comme "réels" ou "générés". L'objectif est le point selle du jeu Minimax \cite{goodfellow2014generative} :
\begin{equation}
    \min_G \max_D V(D, G) = \mathbb{E}_{x \sim p_{\text{data}}(x)} [\log D(x)] + \mathbb{E}_{z \sim p_z(z)} [\log(1 - D(G(z)))]
\end{equation}
Pour les graphes, l'instabilité de l'entraînement GAN est exacerbée par la nature discrète des données.

\section{Modèles de Diffusion Probabiliste (DDPM / Latent Diffusion)}
Les modèles de diffusion sont inspirés de la thermodynamique hors équilibre \cite{ho2020denoising}.
\subsection{Diffusion Directe (Forward Process)}
On détruit progressivement l'information de la molécule $x_0$ en ajoutant du bruit gaussien sur $T$ étapes :
\begin{equation}
    q(x_t | x_{t-1}) = \mathcal{N}(x_t; \sqrt{1 - \beta_t} x_{t-1}, \beta_t I)
\end{equation}

\subsection{Diffusion Inverse (Reverse Process)}
Le but est d'apprendre à inverser ce processus pour recréer la structure moléculaire à partir du bruit pur :
\begin{equation}
    p_\theta(x_{t-1} | x_t) = \mathcal{N}(x_{t-1}; \mu_\theta(x_t, t), \Sigma_\theta(x_t, t))
\end{equation}

\chapter{Méthodologie et Architectures Implémentées}

Nous avons conçu et implémenté trois architectures distinctes pour explorer différentes stratégies de génération. Toutes partagent un socle commun basé sur PyTorch Geometric et utilisent le dataset QM9 \cite{ramakrishnan2014qm9}.

\section{Préparation des Données : Dataset QM9}
QM9 contient 134k molécules organiques stables.
\begin{itemize}
    \item \textbf{Encodage} : {H: 0, C: 1, N: 2, O: 3, F: 4}.
    \item \textbf{Graphes} : $N_{max}=29$ avec padding.
\end{itemize}

\section{Architecture 1 : C-GLD (Conditional Graph Latent Diffusion)}
Ce modèle effectue la diffusion dans un espace latent compressé par un VAE.

\begin{figure}[H]
    \centering
    \fbox{\begin{minipage}[c][8cm]{\linewidth}
        \centering \Huge \textbf{SCHEMA C-GLD ARCHITECTURE}
    \end{minipage}}
    \caption{Architecture C-GLD : VAE + Diffusion Latente.}
\end{figure}

\subsection{Détails Techniques}
\begin{itemize}
    \item \textbf{Encoder} : GATv2 à 3 couches.
    \item \textbf{Latent} : 64 dimensions.
    \item \textbf{Diffusion} : 1000 timesteps avec Cosine Schedule. Conditionnement par concaténation.
\end{itemize}

\section{Architecture 2 : GraphGAN \& GraphGAN-VAE}
Fusion VAE, GAN et Diffusion. Le VAE génère des latents, le GAN critique ces latents pour assurer leur réalisme gaussien.

\begin{figure}[H]
    \centering
    \fbox{\begin{minipage}[c][8cm]{\linewidth}
        \centering \Huge \textbf{SCHEMA GAN-VAE ARCHITECTURE}
    \end{minipage}}
    \caption{Architecture du GraphGAN-VAE avec discrimination latente.}
\end{figure}

\section{Architecture 3 : Ultimate Gen}
Utilise des connectivités résiduelles profondes et un mécanisme d'attention global.

\begin{figure}[H]
    \centering
    \fbox{\begin{minipage}[c][8cm]{\linewidth}
        \centering \Huge \textbf{SCHEMA ULTIMATE GEN}
    \end{minipage}}
    \caption{Architecture UltimateGen : Graph Transformer Encoder + Diffusion Decoder.}
\end{figure}

\chapter{Expérimentations et Résultats}

\section{Synthèse Globale}
Le Tableau 4.1 présente la comparaison directe des métriques.

\begin{table}[H]
    \centering
    \begin{tabular}{@{}lccccc@{}}
    \toprule
    \textbf{Métrique} & \textbf{Graph GAN-VAE} & \textbf{Graph GAN} & \textbf{C-GLD} & \textbf{Ultimate Gen} & \textbf{QM9 (Ref)} \\ \midrule
    \textbf{Validité} & \textbf{100.00\%} & 100.00\% & \textbf{100.00\%} & \textbf{100.00\%} & 100\% \\
    \textbf{Unicité} & 98.50\% & 98.00\% & \textbf{100.00\%} & 99.50\% & 100\% \\
    \textbf{Nouveauté} & \textbf{100.00\%} & \textbf{100.00\%} & \textbf{100.00\%} & \textbf{100.00\%} & - \\
    QED (Moy) & \textbf{0.495} & 0.386 & 0.217 & 0.327 & 0.612 \\
    LogP (Moy) & \textbf{0.640} & 0.567 & -0.752 & -0.179 & 1.28 \\
    Sim. (Max) & 0.196 & 0.214 & \textbf{0.182} & 0.208 & 1.0 \\ \bottomrule
    \end{tabular}
    \caption{Tableau récapitulatif des performances.}
    \label{tab:results}
\end{table}

\section{Analyse Détaillée par Modèle}

\subsection{C-GLD : Exploration de la Diversité}
Le modèle C-GLD montre une capacité exceptionnelle à générer des molécules uniques (100\% d'unicité). Cependant, l'analyse des propriétés (Figure 4.4 et 4.5) révèle une distribution décalée vers des molécules plus simples.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\linewidth]{assets/C-GLD/samples.png}
    \caption{Molécules générées par C-GLD. On observe une bonne validité topologique.}
\end{figure}

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.48\textwidth}
        \includegraphics[width=\textwidth]{assets/C-GLD/qed_distribution.png}
        \caption{Distribution QED}
    \end{subfigure}
    \begin{subfigure}[b]{0.48\textwidth}
        \includegraphics[width=\textwidth]{assets/C-GLD/logp_distribution.png}
        \caption{Distribution LogP}
    \end{subfigure}
    \caption{Analyse des propriétés C-GLD. Le LogP négatif indique des molécules préférentiellement hydrophiles/polaires.}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\linewidth]{assets/C-GLD/similarity_distribution.png}
    \caption{La similarité (C-GLD) reste faible, prouvant l'absence de mémorisation du dataset QM9.}
\end{figure}

\subsection{GraphGAN : L'Approche Adversariale Pure}
Le modèle GraphGAN (sans VAE) produit des résultats intéressants en termes de solubilité et de "Drug Likeness".

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\linewidth]{assets/GraphGAN/samples.png}
    \caption{Échantillons générés par GraphGAN.}
\end{figure}

L'analyse de la solubilité (Figure 4.8) est un atout de ce modèle.

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.48\textwidth}
        \includegraphics[width=\textwidth]{assets/GraphGAN/solubilite.png}
        \caption{Distribution de Solubilité}
    \end{subfigure}
    \begin{subfigure}[b]{0.48\textwidth}
        \includegraphics[width=\textwidth]{assets/GraphGAN/drug_likeness.png}
        \caption{Score de Drug Likeness}
    \end{subfigure}
    \caption{Analyse pharmacologique avancée du GraphGAN.}
\end{figure}

Les distributions classiques (QED, LogP) sont cohérentes avec les autres modèles.

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.3\textwidth}
        \includegraphics[width=\textwidth]{assets/GraphGAN/qed_distribution.png}
        \caption{QED}
    \end{subfigure}
    \begin{subfigure}[b]{0.3\textwidth}
        \includegraphics[width=\textwidth]{assets/GraphGAN/logp_distribution.png}
        \caption{LogP}
    \end{subfigure}
    \begin{subfigure}[b]{0.3\textwidth}
        \includegraphics[width=\textwidth]{assets/GraphGAN/similarity_distribution.png}
        \caption{Similarité}
    \end{subfigure}
    \caption{Métriques standards pour GraphGAN.}
\end{figure}


\subsection{GraphGAN-VAE : Le Meilleur Compromis}
L'ajout du VAE stabilise considérablement le GAN. C'est ce modèle qui obtient le meilleur score QED moyen (0.495).

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\linewidth]{assets/GraphGAN-VAE/generated_molecules_graphgan.png}
    \caption{Molécules générées par GraphGAN-VAE (Haute fidélité).}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{assets/GraphGAN-VAE/qed_distribution.png}
    \caption{Distribution QED du GraphGAN-VAE. On note une "bosse" vers 0.6, montrant une capacité à générer des molécules "drug-like" complexes.}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\linewidth]{assets/GraphGAN-VAE/dist_similarity.png}
    \caption{Similarité vs Train (GraphGAN-VAE).}
\end{figure}

\subsection{Ultimate Gen : L'État de l'Art}
UltimateGen, avec son architecture "Transformer + Diffusion", offre une grande flexibilité.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\linewidth]{assets/UltimateGen/samples.png}
    \caption{Échantillons issus de Ultimate Gen.}
\end{figure}

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.48\textwidth}
        \includegraphics[width=\textwidth]{assets/UltimateGen/qed_distribution.png}
        \caption{QED Ultimate}
    \end{subfigure}
    \begin{subfigure}[b]{0.48\textwidth}
        \includegraphics[width=\textwidth]{assets/UltimateGen/logp_distribution.png}
        \caption{LogP Ultimate}
    \end{subfigure}
    \caption{Analyse des propriétés pour Ultimate Gen.}
\end{figure}


\chapter{Discussion et Conclusion}

\section{Discussion}
L'ensemble des résultats démontre que l'architecture hybride est cru:
\begin{enumerate}
    \item \textbf{Validité} : Le problème de la validité chimique, longtemps un obstacle pour les modèles génératifs de graphes, est ici résolu (100\% validité) grâce à l'utilisation de méthodes de correction de valence implicites dans le décodeur et le processus de diffusion.
    \item \textbf{Diversité vs Qualité} : On retrouve le compromis classique. GraphGAN-VAE offre la meilleure qualité (QED) car le GAN "pousse" vers des structures réalistes. C-GLD offre la meilleure diversité (LogP plus étalé) grâce à la nature stochastique de la diffusion.
    \item \textbf{Stabilité} : GraphGAN pur est difficile à entraîner. L'hybridation avec VAE (GraphGAN-VAE) ou le passage à la diffusion pure (UltimateGen) sont des solutions robustes.
\end{enumerate}

\section{Conclusion}
Au terme de ce projet, nous avons validé une plateforme capable de générer de nouvelles molécules bio-compatibles. L'architecture \textbf{GraphGAN-VAE} s'impose comme la plus performante pour la génération de molécules \textit{drug-like} immédiates, tandis que \textbf{UltimateGen} représente un potentiel de recherche futur pour des espaces chimiques plus vastes. Ces modèles ouvrent la voie à une accélération significative de la découverte de médicaments.

\printbibliography

\end{document}
